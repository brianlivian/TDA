{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77da3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gtda.time_series import SlidingWindow\n",
    "from gtda.diagrams import PersistenceLandscape\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "pd.set_option('display.max_columns', None)\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# !pip install spectrum \n",
    "# from spectrum.periodogram import speriodogram\n",
    "\n",
    "import statsmodels\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "\n",
    "from pylab import *\n",
    "\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73404e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compute the Lp norms\n",
    "# Find the range of x values from the persistence diagram:\n",
    "def Ftseq(diagram):\n",
    "    births =[]\n",
    "    deaths =[]\n",
    "    for pair in diagram:\n",
    "        if pair[2] == 1:\n",
    "            births.append(pair[0])\n",
    "            deaths.append(pair[1])\n",
    "    return np.linspace(min(births), max(deaths), 100)\n",
    "\n",
    "# Calculate Lp norm:\n",
    "def Lpnorm(tseq, landscapevalues, p = 1):\n",
    "    norms = []\n",
    "    if p == 'aucoriginal':\n",
    "        layervalues = landscapevalues[layers]\n",
    "        for point in zip(tseq,layervalues):\n",
    "            norms.append(np.trapz(layervalues, tseq))\n",
    "        return(sum(norms))\n",
    "    elif p == 'aucUpdated':\n",
    "        layervalues = landscapevalues[layers]\n",
    "        return (np.trapz(layervalues))\n",
    "    else:\n",
    "        normvalues = []\n",
    "        for layer in range(layers, 2*layers):\n",
    "            layervalues = landscapevalues[layer]\n",
    "            normvalue = np.linalg.norm(layervalues,p)**p\n",
    "            if normvalue == 0:\n",
    "                break\n",
    "            else: \n",
    "                normvalues.append(normvalue)\n",
    "        return (np.sum(normvalues)**(1/p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b27041",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 80, .1)\n",
    "f1 =  math.pi * (1/4)\n",
    "y1 = (np.sin(f1*x) \n",
    "#             + np.random.normal(scale=.1, size=len(x))\n",
    "\n",
    "        )\n",
    "# y1 = np.round(y1, 5)\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(x,y1)\n",
    "plt.show()\n",
    "print('period = ' + str(2*math.pi/f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537568c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectrum import Periodogram\n",
    "p = Periodogram(y1\n",
    "#                 , sampling=len(simulated_data1)\n",
    "               )\n",
    "p.run()\n",
    "p.plot(sides='onesided')\n",
    "plt.title('Periodogram of Time Series 1')\n",
    "# plt.xlim([0,.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x':x,\n",
    "              'y':y1})\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4779f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_data = pd.DataFrame({'Simulated Data 1' : y1\n",
    "             })\n",
    "simulated_data['Simulated Data 2'] = simulated_data['Simulated Data 1'].shift(0)\n",
    "simulated_data = simulated_data.dropna()\n",
    "(simulated_data['Simulated Data 1'] == simulated_data['Simulated Data 2']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_data = pd.DataFrame({'Simulated Data 1' : y1\n",
    "             })\n",
    "simulated_data['Simulated Data 2'] = simulated_data['Simulated Data 1'].shift(80)\n",
    "simulated_data = simulated_data.dropna()\n",
    "(simulated_data['Simulated Data 1'] == simulated_data['Simulated Data 2']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c498b98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from spectrum import Periodogram\n",
    "p = Periodogram(y1\n",
    "#                 , sampling=len(simulated_data1)\n",
    "               )\n",
    "p.run()\n",
    "\n",
    "for lag in range(10,20, 10):\n",
    "    simulated_data = pd.DataFrame({'Simulated Data 1' : y1\n",
    "                 })\n",
    "    simulated_data['Simulated Data 2'] = simulated_data['Simulated Data 1'].shift(lag)\n",
    "    simulated_data = simulated_data.dropna()\n",
    "\n",
    "    # Create point cloud\n",
    "    window_size = 160\n",
    "    stride = 1\n",
    "    df = simulated_data\n",
    "    X = df\n",
    "    y = df.index\n",
    "    SW = SlidingWindow(size=window_size, stride=stride)\n",
    "    X_sw, yr = SW.fit_transform_resample(X, y)\n",
    "\n",
    "    # Calculate the norms for each of the windows in the multivariate sliding window\n",
    "    variabilitys = np.empty(window_size -1)\n",
    "    variabilitys[:] = np.nan\n",
    "    variabilitys = list(variabilitys)\n",
    "\n",
    "    correlations = np.empty(window_size -1)\n",
    "    correlations[:] = np.nan\n",
    "    correlations = list(correlations)\n",
    "    \n",
    "    Norms = np.empty(window_size-1)\n",
    "    Norms[:] = np.nan\n",
    "    Norms = list(Norms)\n",
    "    \n",
    "    vrp = VietorisRipsPersistence()\n",
    "    pl = PersistenceLandscape()\n",
    "    for pointcloud in X_sw:\n",
    "        persistencediagram = vrp.fit_transform(pointcloud.reshape(1, *pointcloud.shape))\n",
    "        landscapedata = pl.fit_transform(persistencediagram)\n",
    "        tseq = Ftseq(persistencediagram[0])\n",
    "        yvalues = landscapedata[0][1]\n",
    "        Norms.append(Lpnorm(tseq, yvalues, p = 'auc'))    \n",
    "    \n",
    "        pointcloudcovmatrix = np.array(pd.DataFrame(pointcloud).cov())\n",
    "        variabilitys.append((pointcloudcovmatrix[0][0]  + pointcloudcovmatrix[1][1]) / 2)\n",
    "    \n",
    "        pointcloudcorrmatrix = np.array(pd.DataFrame(pointcloud).corr())\n",
    "        correlations.append(pointcloudcorrmatrix[0][1])\n",
    "    \n",
    "\n",
    "    \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    data_scaled = min_max_scaler.fit_transform(simulated_data.values)\n",
    "    data_scaled = pd.DataFrame(data_scaled, columns = simulated_data.columns, index = simulated_data.index)\n",
    "#     data_scaled['L1 Norm'] = min_max_scaler.fit_transform(np.array(Norms).reshape(-1, 1)).reshape(-1)\n",
    "#     data_scaled['Variability'] = min_max_scaler.fit_transform(np.array(variabilitys).reshape(-1, 1)).reshape(-1)\n",
    "    data_scaled['L1 Norm'] = np.array(Norms) / pd.Series(Norms).max() if pd.Series(Norms).max() != 0 else np.array(Norms)*0\n",
    "    data_scaled['Variability'] = np.array(variabilitys) / pd.Series(variabilitys).max() if pd.Series(variabilitys).max() != 0 else np.array(variabilitys)*0\n",
    "    data_scaled['Correlation'] = min_max_scaler.fit_transform(np.array(correlations).reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "    \n",
    "#     plt.figure(figsize = (20,12), facecolor = 'white')\n",
    "#     plt.subplot(2,1,1)\n",
    "#     plt.plot(data_scaled['Simulated Data 1'], color = 'blue', label = 'Simulated Data 1')\n",
    "#     plt.plot(data_scaled['Simulated Data 2'], color = 'red', label = 'Simulated Data 2')\n",
    "#     plt.title('Lag ' + str(lag))\n",
    "#     plt.xlim([0, 1000])\n",
    "#     plt.legend()\n",
    "    \n",
    "#     plt.subplot(2,1,2)\n",
    "#     plt.plot(data_scaled['Variability'], color = 'blueviolet', label = 'Variability')\n",
    "#     plt.plot(data_scaled['L1 Norm'], color = 'black', label = 'L1 Norm')\n",
    "#     plt.xlim([0, 1000])\n",
    "#     plt.legend()\n",
    "    \n",
    "#     plt.subplot(3,1,3)\n",
    "#     plt.plot(data_scaled['Variability'], color = 'purple', label = 'Variability')\n",
    "#     plt.plot(data_scaled['Correlation'], color = 'orange', label = 'Correlation')\n",
    "#     plt.xlim([0, 1000])\n",
    "#     plt.legend()\n",
    "#     plt.savefig('/Users/brianlivian/Desktop/Sine Lag Delays - No Noise' + ' ' +str(lag))\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "    Gtop = gridspec.GridSpec(3, 3, hspace = 0)\n",
    "    Gbot = gridspec.GridSpec(3, 3, hspace = 1, wspace = .5)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "\n",
    "    ax1 = plt.subplot(Gtop[0,:])\n",
    "    ax1.plot(data_scaled['Simulated Data 1'], color = 'blue', label = 'Simulated Data 1')\n",
    "    ax1.plot(data_scaled['Simulated Data 2'], color = 'red', label = 'Simulated Data 2')\n",
    "    plt.title('Lag ' + str(lag), fontsize=10)\n",
    "    plt.legend()\n",
    "    ax2 = plt.subplot(Gtop[1,:], sharex = ax1, sharey = ax1)\n",
    "    ax2.plot(data_scaled['Variability'], color = 'blueviolet', label = 'Variability')\n",
    "    ax2.plot(data_scaled['L1 Norm'], color = 'black', label = 'L1 Norm')\n",
    "    ax2.plot(correlations, color = 'orange', label = 'Correlation')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(Gbot[2,0])\n",
    "    p.plot(sides='onesided')\n",
    "    plt.title('Periodogram of Time Series 1')\n",
    "    plt.subplot(Gbot[2, 1])\n",
    "    plt.csd(simulated_data['Simulated Data 1'], simulated_data['Simulated Data 2'])\n",
    "    plt.title('CSD of TS1 vs TS2')\n",
    "    plt.subplot(Gbot[2, 2])\n",
    "    sns.scatterplot(simulated_data['Simulated Data 1'], simulated_data['Simulated Data 2'])\n",
    "    plt.title('Simulated Data Scatter Plot')\n",
    "    \n",
    "#     plt.suptitle('Lag ' + str(lag), fontsize=10)\n",
    "#     plt.savefig('/Users/brianlivian/Desktop/Sine Lag Delays - No Noise' + ' ' +str(lag))\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f27bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae963435",
   "metadata": {},
   "source": [
    "## Moderate Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x = np.linspace(0, 100, 1000)\n",
    "f1 =  math.pi * (1/4)\n",
    "y1 = (np.sin(f1*x) \n",
    "            + np.random.normal(scale=.3, size=len(x))\n",
    "\n",
    "        )\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(x,y1)\n",
    "plt.show()\n",
    "print('period = ' + str(2*math.pi/f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bbf39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through window by window\n",
    "# see whats going on in the 0 noise, why l1's are rising and rectangular\n",
    "# show rips diagram, scatter plot by windows\n",
    "# add correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4fc819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectrum import Periodogram\n",
    "p = Periodogram(y1\n",
    "#                 , sampling=len(simulated_data1)\n",
    "               )\n",
    "p.run()\n",
    "\n",
    "for lag in range(0,90, 10):\n",
    "    simulated_data = pd.DataFrame({'Simulated Data 1' : y1\n",
    "                 })\n",
    "    simulated_data['Simulated Data 2'] = simulated_data['Simulated Data 1'].shift(lag)\n",
    "    simulated_data = simulated_data.dropna()\n",
    "\n",
    "    # Create point cloud\n",
    "    window_size = 150\n",
    "    stride = 1\n",
    "    df = simulated_data\n",
    "    X = df\n",
    "    y = df.index\n",
    "    SW = SlidingWindow(size=window_size, stride=stride)\n",
    "    X_sw, yr = SW.fit_transform_resample(X, y)\n",
    "\n",
    "    # Calculate the norms for each of the windows in the multivariate sliding window\n",
    "    variabilitys = np.empty(window_size -1)\n",
    "    variabilitys[:] = np.nan\n",
    "    variabilitys = list(variabilitys)\n",
    "\n",
    "    correlations = np.empty(window_size -1)\n",
    "    correlations[:] = np.nan\n",
    "    correlations = list(correlations)\n",
    "    \n",
    "    Norms = np.empty(window_size-1)\n",
    "    Norms[:] = np.nan\n",
    "    Norms = list(Norms)\n",
    "    layers = 100\n",
    "    vrp = VietorisRipsPersistence()\n",
    "    pl = PersistenceLandscape(layers)\n",
    "    for pointcloud in X_sw:\n",
    "        persistencediagram = vrp.fit_transform(pointcloud.reshape(1, *pointcloud.shape))\n",
    "        landscapedata = pl.fit_transform(persistencediagram)\n",
    "        tseq = Ftseq(persistencediagram[0])\n",
    "        Norms.append(Lpnorm(tseq, landscapedata[0], p = 'aucUpdated'))    \n",
    "    \n",
    "        pointcloudcovmatrix = np.array(pd.DataFrame(pointcloud).cov())\n",
    "        variabilitys.append((pointcloudcovmatrix[0][0]  + pointcloudcovmatrix[1][1]) / 2)\n",
    "    \n",
    "        pointcloudcorrmatrix = np.array(pd.DataFrame(pointcloud).corr())\n",
    "        correlations.append(pointcloudcorrmatrix[0][1])\n",
    "    \n",
    "\n",
    "    \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    data_scaled = min_max_scaler.fit_transform(simulated_data.values)\n",
    "    data_scaled = pd.DataFrame(data_scaled, columns = simulated_data.columns, index = simulated_data.index)\n",
    "    data_scaled['L1 Norm'] = min_max_scaler.fit_transform(np.array(Norms).reshape(-1, 1)).reshape(-1)\n",
    "    data_scaled['Variability'] = min_max_scaler.fit_transform(np.array(variabilitys).reshape(-1, 1)).reshape(-1)\n",
    "    data_scaled['Correlation'] = min_max_scaler.fit_transform(np.array(correlations).reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "    \n",
    "#     plt.figure(figsize = (20,12), facecolor = 'white')\n",
    "#     plt.subplot(2,1,1)\n",
    "#     plt.plot(data_scaled['Simulated Data 1'], color = 'blue', label = 'Simulated Data 1')\n",
    "#     plt.plot(data_scaled['Simulated Data 2'], color = 'red', label = 'Simulated Data 2')\n",
    "#     plt.title('Lag ' + str(lag))\n",
    "#     plt.xlim([0, 1000])\n",
    "#     plt.legend()\n",
    "    \n",
    "#     plt.subplot(2,1,2)\n",
    "#     plt.plot(data_scaled['Variability'], color = 'blueviolet', label = 'Variability')\n",
    "#     plt.plot(data_scaled['L1 Norm'], color = 'black', label = 'L1 Norm')\n",
    "#     plt.xlim([0, 1000])\n",
    "#     plt.legend()\n",
    "    \n",
    "#     plt.subplot(3,1,3)\n",
    "#     plt.plot(data_scaled['Variability'], color = 'purple', label = 'Variability')\n",
    "#     plt.plot(data_scaled['Correlation'], color = 'orange', label = 'Correlation')\n",
    "#     plt.xlim([0, 1000])\n",
    "#     plt.legend()\n",
    "#     plt.savefig('/Users/brianlivian/Desktop/Sine Lag Delays - Moderate Noise' + ' ' +str(lag))\n",
    "#     plt.show()\n",
    "    \n",
    "    Gtop = gridspec.GridSpec(3, 3, hspace = 0)\n",
    "    Gbot = gridspec.GridSpec(3, 3, hspace = 1, wspace = .5)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "\n",
    "    ax1 = plt.subplot(Gtop[0,:])\n",
    "    ax1.plot(data_scaled['Simulated Data 1'], color = 'blue', label = 'Simulated Data 1')\n",
    "    ax1.plot(data_scaled['Simulated Data 2'], color = 'red', label = 'Simulated Data 2')\n",
    "    plt.title('Lag ' + str(lag), fontsize=10)\n",
    "    plt.legend()\n",
    "    ax2 = plt.subplot(Gtop[1,:], sharex = ax1)\n",
    "    ax2.plot(data_scaled['Variability'], color = 'blueviolet', label = 'Variability')\n",
    "    ax2.plot(data_scaled['L1 Norm'], color = 'black', label = 'L1 Norm')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(Gbot[2,0])\n",
    "    p.plot(sides='onesided')\n",
    "    plt.title('Periodogram of Time Series 1')\n",
    "    plt.subplot(Gbot[2, 1])\n",
    "    plt.csd(simulated_data['Simulated Data 1'], simulated_data['Simulated Data 2'])\n",
    "    plt.title('CSD of TS1 vs TS2')\n",
    "    plt.subplot(Gbot[2, 2])\n",
    "    sns.scatterplot(simulated_data['Simulated Data 1'], simulated_data['Simulated Data 2'])\n",
    "    plt.title('Simulated Data Scatter Plot')\n",
    "    \n",
    "#     plt.suptitle('Lag ' + str(lag), fontsize=10)\n",
    "#     plt.savefig('/Users/brianlivian/Desktop/Sine Lag Delays - Moderate Noise' + ' ' +str(lag))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c1711",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from spectrum import Periodogram\n",
    "p = Periodogram(y1\n",
    "#                 , sampling=len(simulated_data1)\n",
    "               )\n",
    "p.run()\n",
    "\n",
    "for lag in range(0,90, 10):\n",
    "    simulated_data = pd.DataFrame({'Simulated Data 1' : y1\n",
    "                 })\n",
    "    simulated_data['Simulated Data 2'] = simulated_data['Simulated Data 1'].shift(lag)\n",
    "    simulated_data = simulated_data.dropna()\n",
    "\n",
    "    # Create point cloud\n",
    "    window_size = 150\n",
    "    stride = 1\n",
    "    df = simulated_data\n",
    "    X = df\n",
    "    y = df.index\n",
    "    SW = SlidingWindow(size=window_size, stride=stride)\n",
    "    X_sw, yr = SW.fit_transform_resample(X, y)\n",
    "\n",
    "    # Calculate the norms for each of the windows in the multivariate sliding window\n",
    "    variabilitys = np.empty(window_size -1)\n",
    "    variabilitys[:] = np.nan\n",
    "    variabilitys = list(variabilitys)\n",
    "\n",
    "    correlations = np.empty(window_size -1)\n",
    "    correlations[:] = np.nan\n",
    "    correlations = list(correlations)\n",
    "    \n",
    "    Norms = np.empty(window_size-1)\n",
    "    Norms[:] = np.nan\n",
    "    Norms = list(Norms)\n",
    "    layers = 100\n",
    "    vrp = VietorisRipsPersistence()\n",
    "    pl = PersistenceLandscape(layers)\n",
    "    for pointcloud in X_sw:\n",
    "        persistencediagram = vrp.fit_transform(pointcloud.reshape(1, *pointcloud.shape))\n",
    "        landscapedata = pl.fit_transform(persistencediagram)\n",
    "        tseq = Ftseq(persistencediagram[0])\n",
    "        Norms.append(Lpnorm(tseq, landscapedata[0], p = 1))    \n",
    "    \n",
    "        pointcloudcovmatrix = np.array(pd.DataFrame(pointcloud).cov())\n",
    "        variabilitys.append((pointcloudcovmatrix[0][0]  + pointcloudcovmatrix[1][1]) / 2)\n",
    "    \n",
    "        pointcloudcorrmatrix = np.array(pd.DataFrame(pointcloud).corr())\n",
    "        correlations.append(pointcloudcorrmatrix[0][1])\n",
    "    \n",
    "\n",
    "    \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    data_scaled = min_max_scaler.fit_transform(simulated_data.values)\n",
    "    data_scaled = pd.DataFrame(data_scaled, columns = simulated_data.columns, index = simulated_data.index)\n",
    "    data_scaled['L1 Norm'] = min_max_scaler.fit_transform(np.array(Norms).reshape(-1, 1)).reshape(-1)\n",
    "    data_scaled['Variability'] = min_max_scaler.fit_transform(np.array(variabilitys).reshape(-1, 1)).reshape(-1)\n",
    "    data_scaled['Correlation'] = min_max_scaler.fit_transform(np.array(correlations).reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "    \n",
    "#     plt.figure(figsize = (20,12), facecolor = 'white')\n",
    "#     plt.subplot(2,1,1)\n",
    "#     plt.plot(data_scaled['Simulated Data 1'], color = 'blue', label = 'Simulated Data 1')\n",
    "#     plt.plot(data_scaled['Simulated Data 2'], color = 'red', label = 'Simulated Data 2')\n",
    "#     plt.title('Lag ' + str(lag))\n",
    "#     plt.xlim([0, 1000])\n",
    "#     plt.legend()\n",
    "    \n",
    "#     plt.subplot(2,1,2)\n",
    "#     plt.plot(data_scaled['Variability'], color = 'blueviolet', label = 'Variability')\n",
    "#     plt.plot(data_scaled['L1 Norm'], color = 'black', label = 'L1 Norm')\n",
    "#     plt.xlim([0, 1000])\n",
    "#     plt.legend()\n",
    "    \n",
    "#     plt.subplot(3,1,3)\n",
    "#     plt.plot(data_scaled['Variability'], color = 'purple', label = 'Variability')\n",
    "#     plt.plot(data_scaled['Correlation'], color = 'orange', label = 'Correlation')\n",
    "#     plt.xlim([0, 1000])\n",
    "#     plt.legend()\n",
    "#     plt.savefig('/Users/brianlivian/Desktop/Sine Lag Delays - Moderate Noise' + ' ' +str(lag))\n",
    "#     plt.show()\n",
    "    \n",
    "    Gtop = gridspec.GridSpec(3, 3, hspace = 0)\n",
    "    Gbot = gridspec.GridSpec(3, 3, hspace = 1, wspace = .5)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "\n",
    "    ax1 = plt.subplot(Gtop[0,:])\n",
    "    ax1.plot(data_scaled['Simulated Data 1'], color = 'blue', label = 'Simulated Data 1')\n",
    "    ax1.plot(data_scaled['Simulated Data 2'], color = 'red', label = 'Simulated Data 2')\n",
    "    plt.title('Lag ' + str(lag), fontsize=10)\n",
    "    plt.legend()\n",
    "    ax2 = plt.subplot(Gtop[1,:], sharex = ax1)\n",
    "    ax2.plot(data_scaled['Variability'], color = 'blueviolet', label = 'Variability')\n",
    "    ax2.plot(data_scaled['L1 Norm'], color = 'black', label = 'L1 Norm')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(Gbot[2,0])\n",
    "    p.plot(sides='onesided')\n",
    "    plt.title('Periodogram of Time Series 1')\n",
    "    plt.subplot(Gbot[2, 1])\n",
    "    plt.csd(simulated_data['Simulated Data 1'], simulated_data['Simulated Data 2'])\n",
    "    plt.title('CSD of TS1 vs TS2')\n",
    "    plt.subplot(Gbot[2, 2])\n",
    "    sns.scatterplot(simulated_data['Simulated Data 1'], simulated_data['Simulated Data 2'])\n",
    "    plt.title('Simulated Data Scatter Plot')\n",
    "    \n",
    "#     plt.suptitle('Lag ' + str(lag), fontsize=10)\n",
    "#     plt.savefig('/Users/brianlivian/Desktop/Sine Lag Delays - Moderate Noise' + ' ' +str(lag))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631cff18",
   "metadata": {},
   "source": [
    "## Large Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fea05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 100, 1000)\n",
    "f1 =  math.pi * (1/4)\n",
    "y1 = (np.sin(f1*x) \n",
    "            + np.random.normal(scale=1, size=len(x))\n",
    "\n",
    "        )\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(x,y1)\n",
    "plt.show()\n",
    "print('period = ' + str(2*math.pi/f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f28cfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from spectrum import Periodogram\n",
    "p = Periodogram(y1\n",
    "#                 , sampling=len(simulated_data1)\n",
    "               )\n",
    "p.run()\n",
    "\n",
    "\n",
    "for lag in range(0,90, 10):\n",
    "    simulated_data = pd.DataFrame({'Simulated Data 1' : y1\n",
    "                 })\n",
    "    simulated_data['Simulated Data 2'] = simulated_data['Simulated Data 1'].shift(lag)\n",
    "    simulated_data = simulated_data.dropna()\n",
    "\n",
    "    # Create point cloud\n",
    "    window_size = 150\n",
    "    stride = 1\n",
    "    df = simulated_data\n",
    "    X = df\n",
    "    y = df.index\n",
    "    SW = SlidingWindow(size=window_size, stride=stride)\n",
    "    X_sw, yr = SW.fit_transform_resample(X, y)\n",
    "\n",
    "    # Calculate the norms for each of the windows in the multivariate sliding window\n",
    "    variabilitys = np.empty(window_size -1)\n",
    "    variabilitys[:] = np.nan\n",
    "    variabilitys = list(variabilitys)\n",
    "\n",
    "    correlations = np.empty(window_size -1)\n",
    "    correlations[:] = np.nan\n",
    "    correlations = list(correlations)\n",
    "    \n",
    "    Norms = np.empty(window_size-1)\n",
    "    Norms[:] = np.nan\n",
    "    Norms = list(Norms)\n",
    "    vrp = VietorisRipsPersistence()\n",
    "    pl = PersistenceLandscape()\n",
    "    for pointcloud in X_sw:\n",
    "        persistencediagram = vrp.fit_transform(pointcloud.reshape(1, *pointcloud.shape))\n",
    "        landscapedata = pl.fit_transform(persistencediagram)\n",
    "        tseq = Ftseq(persistencediagram[0])\n",
    "        yvalues = landscapedata[0][1]\n",
    "        Norms.append(Lpnorm(tseq, yvalues, p = 'auc'))    \n",
    "    \n",
    "        pointcloudcovmatrix = np.array(pd.DataFrame(pointcloud).cov())\n",
    "        variabilitys.append((pointcloudcovmatrix[0][0]  + pointcloudcovmatrix[1][1]) / 2)\n",
    "    \n",
    "        pointcloudcorrmatrix = np.array(pd.DataFrame(pointcloud).corr())\n",
    "        correlations.append(pointcloudcorrmatrix[0][1])\n",
    "    \n",
    "\n",
    "    \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    data_scaled = min_max_scaler.fit_transform(simulated_data.values)\n",
    "    data_scaled = pd.DataFrame(data_scaled, columns = simulated_data.columns, index = simulated_data.index)\n",
    "    data_scaled['L1 Norm'] = min_max_scaler.fit_transform(np.array(Norms).reshape(-1, 1)).reshape(-1)\n",
    "    data_scaled['Variability'] = min_max_scaler.fit_transform(np.array(variabilitys).reshape(-1, 1)).reshape(-1)\n",
    "    data_scaled['Correlation'] = min_max_scaler.fit_transform(np.array(correlations).reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "\n",
    "    Gtop = gridspec.GridSpec(3, 3, hspace = 0)\n",
    "    Gbot = gridspec.GridSpec(3, 3, hspace = 1, wspace = .5)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "\n",
    "    ax1 = plt.subplot(Gtop[0,:])\n",
    "    ax1.plot(data_scaled['Simulated Data 1'], color = 'blue', label = 'Simulated Data 1')\n",
    "    ax1.plot(data_scaled['Simulated Data 2'], color = 'red', label = 'Simulated Data 2')\n",
    "    plt.title('Lag ' + str(lag), fontsize=10)\n",
    "    plt.legend()\n",
    "    ax2 = plt.subplot(Gtop[1,:], sharex = ax1)\n",
    "    ax2.plot(data_scaled['Variability'], color = 'blueviolet', label = 'Variability')\n",
    "    ax2.plot(data_scaled['L1 Norm'], color = 'black', label = 'L1 Norm')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(Gbot[2,0])\n",
    "    p.plot(sides='onesided')\n",
    "    plt.title('Periodogram of Time Series 1')\n",
    "    plt.subplot(Gbot[2, 1])\n",
    "    plt.csd(simulated_data['Simulated Data 1'], simulated_data['Simulated Data 2'])\n",
    "    plt.title('CSD of TS1 vs TS2')\n",
    "    plt.subplot(Gbot[2, 2])\n",
    "    sns.scatterplot(simulated_data['Simulated Data 1'], simulated_data['Simulated Data 2'])\n",
    "    plt.title('Simulated Data Scatter Plot')\n",
    "    \n",
    "#     plt.suptitle('Lag ' + str(lag), fontsize=10)\n",
    "    plt.savefig('/Users/brianlivian/Desktop/Sine Lag Delays - Large Noise' + ' ' +str(lag))\n",
    "    plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244f0ed",
   "metadata": {},
   "source": [
    "## XLarge Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 100, 1000)\n",
    "f1 =  math.pi * (1/4)\n",
    "y1 = (np.sin(f1*x) \n",
    "            + np.random.normal(scale=3, size=len(x))\n",
    "\n",
    "        )\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(x,y1)\n",
    "plt.show()\n",
    "print('period = ' + str(2*math.pi/f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b620fcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from spectrum import Periodogram\n",
    "p = Periodogram(y1\n",
    "#                 , sampling=len(simulated_data1)\n",
    "               )\n",
    "p.run()\n",
    "\n",
    "for lag in range(0,90, 10):\n",
    "    simulated_data = pd.DataFrame({'Simulated Data 1' : y1\n",
    "                 })\n",
    "    simulated_data['Simulated Data 2'] = simulated_data['Simulated Data 1'].shift(lag)\n",
    "    simulated_data = simulated_data.dropna()\n",
    "\n",
    "    # Create point cloud\n",
    "    window_size = 150\n",
    "    stride = 1\n",
    "    df = simulated_data\n",
    "    X = df\n",
    "    y = df.index\n",
    "    SW = SlidingWindow(size=window_size, stride=stride)\n",
    "    X_sw, yr = SW.fit_transform_resample(X, y)\n",
    "\n",
    "    # Calculate the norms for each of the windows in the multivariate sliding window\n",
    "    variabilitys = np.empty(window_size -1)\n",
    "    variabilitys[:] = np.nan\n",
    "    variabilitys = list(variabilitys)\n",
    "\n",
    "    correlations = np.empty(window_size -1)\n",
    "    correlations[:] = np.nan\n",
    "    correlations = list(correlations)\n",
    "    \n",
    "    Norms = np.empty(window_size-1)\n",
    "    Norms[:] = np.nan\n",
    "    Norms = list(Norms)\n",
    "    vrp = VietorisRipsPersistence()\n",
    "    pl = PersistenceLandscape()\n",
    "    for pointcloud in X_sw:\n",
    "        persistencediagram = vrp.fit_transform(pointcloud.reshape(1, *pointcloud.shape))\n",
    "        landscapedata = pl.fit_transform(persistencediagram)\n",
    "        tseq = Ftseq(persistencediagram[0])\n",
    "        yvalues = landscapedata[0][1]\n",
    "        Norms.append(Lpnorm(tseq, yvalues, p = 'auc'))    \n",
    "    \n",
    "        pointcloudcovmatrix = np.array(pd.DataFrame(pointcloud).cov())\n",
    "        variabilitys.append((pointcloudcovmatrix[0][0]  + pointcloudcovmatrix[1][1]) / 2)\n",
    "    \n",
    "        pointcloudcorrmatrix = np.array(pd.DataFrame(pointcloud).corr())\n",
    "        correlations.append(pointcloudcorrmatrix[0][1])\n",
    "    \n",
    "\n",
    "    \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    data_scaled = min_max_scaler.fit_transform(simulated_data.values)\n",
    "    data_scaled = pd.DataFrame(data_scaled, columns = simulated_data.columns, index = simulated_data.index)\n",
    "    data_scaled['L1 Norm'] = min_max_scaler.fit_transform(np.array(Norms).reshape(-1, 1)).reshape(-1)\n",
    "    data_scaled['Variability'] = min_max_scaler.fit_transform(np.array(variabilitys).reshape(-1, 1)).reshape(-1)\n",
    "    data_scaled['Correlation'] = min_max_scaler.fit_transform(np.array(correlations).reshape(-1, 1)).reshape(-1)\n",
    "    \n",
    "    \n",
    "    Gtop = gridspec.GridSpec(3, 3, hspace = 0)\n",
    "    Gbot = gridspec.GridSpec(3, 3, hspace = 1, wspace = .5)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "\n",
    "    ax1 = plt.subplot(Gtop[0,:])\n",
    "    ax1.plot(data_scaled['Simulated Data 1'], color = 'blue', label = 'Simulated Data 1')\n",
    "    ax1.plot(data_scaled['Simulated Data 2'], color = 'red', label = 'Simulated Data 2')\n",
    "    plt.title('Lag ' + str(lag), fontsize=10)\n",
    "    plt.legend()\n",
    "    ax2 = plt.subplot(Gtop[1,:], sharex = ax1)\n",
    "    ax2.plot(data_scaled['Variability'], color = 'blueviolet', label = 'Variability')\n",
    "    ax2.plot(data_scaled['L1 Norm'], color = 'black', label = 'L1 Norm')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(Gbot[2,0])\n",
    "    p.plot(sides='onesided')\n",
    "    plt.title('Periodogram of Time Series 1')\n",
    "    plt.subplot(Gbot[2, 1])\n",
    "    plt.csd(simulated_data['Simulated Data 1'], simulated_data['Simulated Data 2'])\n",
    "    plt.title('CSD of TS1 vs TS2')\n",
    "    plt.subplot(Gbot[2, 2])\n",
    "    sns.scatterplot(simulated_data['Simulated Data 1'], simulated_data['Simulated Data 2'])\n",
    "    plt.title('Simulated Data Scatter Plot')\n",
    "    \n",
    "#     plt.suptitle('Lag ' + str(lag), fontsize=10)\n",
    "    plt.savefig('/Users/brianlivian/Desktop/Sine Lag Delays - XL Noise' + ' ' +str(lag))\n",
    "    plt.show()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3299d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a17e667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
